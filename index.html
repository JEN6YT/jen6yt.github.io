<!DOCTYPE html>
<html lang="en">    

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles.css">
    <script src="script.js" defer></script>
</head>

<body>
    <header>
        <nav class="nav">
            <div class="logo">
                <a href="#about" data-link>@jenniferzhang 张云童</a>
            </div>
            <button class="nav-toggle" aria-label="Toggle navigation">☰</button>
            <div class="nav-links">
                <a href="#about" data-link>About</a>
                <a href="#projects" data-link>Research</a>
                <a href="#cv" data-link>CV</a>
                <a href="#building" data-link>Building</a>
                <button id="dark-mode-toggle" aria-label="Toggle dark mode">&#9790;</button>
            </div>
        </nav>
    </header>

    <main>
        <section id="about">
            <div class="about-header">
                <div class="about-text">
                    <p>Hi! I am Jennifer. I study
                        <a href="https://engsci.utoronto.ca/" target="_blank">Engineering Science</a> at University of Toronto. 
                        During this program, I have learnt about engineering disciplines, programming skills, and various interdisciplinary topics.
                        In addition, I have developed a strong interest in data science and machine learning.
                        My current research focuses on <b>Large Foundation Models Alignment</b>, <b>Reinforcement Learning</b>, and <b>Agent-Human Alignment</b> (multi-agent interactions and alignment).
                        I am deeply interested in using AI to solve real-world problems, and I am particularly fascinated by the potential of AI to enhance human capabilities, and for social good.
                    </p>
                    <p>In my free time, I enjoy outdoor activities and exploring new technologies. If you would love to have a chat, feel free to shoot me an email! </p>
                </div>
                <div class="about-image">
                    <img src="./assets/jennifer.jpg" alt="Jennifer Zhang" />

                    <div class="icons">
                        <a href="mailto:jenniferyt.zhang@mail.utoronto.ca" target="_blank" aria-label="Email">
                            <img src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons/icons/gmail.svg" alt="Email" />
                        </a>
                        <a href="https://github.com/JEN6YT" target="_blank" aria-label="GitHub">
                            <img src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons/icons/github.svg" alt="GitHub" />
                        </a>
                        <a href="https://www.linkedin.com/in/jennifer-yuntong-zhang-a9225b21b/" target="_blank" aria-label="LinkedIn">
                            <img src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons/icons/linkedin.svg" alt="LinkedIn" />
                        </a>
                        <a href="https://www.instagram.com/jenniferoarz/" target="_blank" aria-label="Instagram">
                            <img src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons/icons/instagram.svg" alt="Instagram" />
                        </a>
                    </div>
                </div>
            </div>
            <img src="assets/sunflower.png" alt="Sunflower" class="decorative-image" />
        </section>

        <section id="projects">
            <div class="project-entry">
                <h3>In-Context Algorithm Emulation in Fixed-Weight Transformers @ MAGICS, Northwestern University</h3>
                <div class="project-callout">
                    <p class="callout-authors">
                        Jerry Yao-Chieh Hu<sup class="big-star">*</sup>, Hude Liu<sup class="big-star">*</sup>, <strong>Jennifer Yuntong Zhang<sup class="big-star">*</sup></strong>, Han Liu<br>
                        In submission to ICLR 2026.
                    </p>
                    <div class="project-actions">
                        <!-- TODO: update link -->
                        <a href="https://arxiv.org/abs/2508.17550" class="btn_pdf">pdf</a>
                        <a href="https://github.com/MAGICS-LAB/algo_emu" class="btn_code">code</a>
                    </div>
                </div>
                <!-- <p>We prove that a minimal Transformer with frozen weights emulates a broad class of algorithms by in-context prompting. 
                    We formalize two modes of in-context algorithm emulation. In the task-specific mode, for any continuous function, we show the existence of a single-head softmax attention layer whose forward pass reproduces machine learning algorithms.
                    In the prompt-programmable mode, we prove universality: a single fixed-weight two-layer softmax attention module emulates all algorithms from the task-specific class (i.e., each implementable by a single softmax attention) via only prompting.
                    Our key idea is to construct prompts that encode an algorithm's parameters into token representations, creating sharp dot-product gaps that force the softmax attention to follow the intended computation.
                    This construction requires no feed-forward layers and no parameter updates. All adaptation happens through the prompt alone. Numerical results corroborate our theory.
                    These findings forge a direct link between in-context learning and algorithmic emulation, and offer a simple mechanism for large Transformers to serve as prompt-programmable libraries of algorithms. 
                    They illuminate how GPT-style foundation models may swap algorithms via prompts alone, and establish a form of algorithmic universality in modern Transformer models.
                </p> -->
            </div>

            <div class="project-entry">
                <h3>Are Hallucinations Bad Estimators? @ MAGICS, Northwestern University</h3>
                <div class="project-callout">
                    <p class="callout-authors">
                        Hude Liu<sup class="big-star">*</sup>, Jerry Yao-Chieh Hu<sup class="big-star">*</sup>, <strong>Jennifer Yuntong Zhang</strong>, Zhao Song, Han Liu<br>
                        In submission to ICLR 2026.
                    </p>
                    <div class="project-actions">
                        <!-- TODO: update link -->
                        <a href="https://www.arxiv.org/abs/2509.21473" class="btn_pdf">pdf</a>
                        <a href="https://github.com/MAGICS-LAB/hallucination" class="btn_code">code</a>
                    </div>
                </div>
                <!-- <p>We formalize hallucinations in generative models as failures to link an estimate to any plausible cause. 
                    Under this interpretation, we show that even loss-minimizing optimal estimators still hallucinate.
                    We confirm this with a general high probability lower bound on hallucinate rate for generic data distributions.
                    This reframes hallucination as structural misalignment between loss minimization and human-acceptable outputs, and hence estimation errors induced by miscalibration.
                    Experiments on coin aggregation, open-ended QA, and text-to-image support our theory.
                </p> -->
            </div>


            <div class="project-entry">
                <h3>WS-GRPO: Weakly-Supervised Group-Relative Policy Optimization @ McAuley Lab, UCSD</h3>
                <!-- <p><em>with <a href="https://cseweb.ucsd.edu/~jmcauley/">Prof. Julian McAuley</a></em></p> -->
                 <div class="project-callout">
                    <p class="callout-authors">
                        Gagan Mundada, Rohan Surana, <strong>Jennifer Yuntong Zhang</strong>, Xintong Li, Tong Yu, Lina Yao, Jingbo Shang, Julian McAuley, Junda Wu<br>
                        In submission to ICLR 2026.
                    </p>
                    <!-- <div class="project-actions">
                        <a href="https://arxiv.org/pdf/2508.17550" class="btn_pdf">pdf</a>
                        <a href="https://github.com/MAGICS-LAB/hallucination" class="btn_code">code</a>
                    </div> -->
                </div>
                <p>Group-Relative Policy Optimization (GRPO) has emerged as an effective approach for training language models on complex reasoning tasks by normalizing rewards within groups of rollouts. 
                    However, GRPO's group-relative advantage estimation critically depends on dense step-wise reward signals throughout the reasoning process. 
                    In practice, obtaining such dense supervision requires expensive human annotations of intermediate reasoning steps or carefully designed step-wise reward functions. 
                    This creates a significant challenge specific to group-relative methods: while GRPO performs best with dense intermediate feedback, real-world scenarios often provide only sparse outcome supervision—such as final answer correctness or binary trajectory labels.
                    We propose Weakly-Supervised Group-Relative Policy Optimization (WS-GRPO), which addresses this unique limitation by learning to extract dense preference signals from sparse outcome supervision while preserving GRPO's group-relative normalization benefits. 
                    WS-GRPO operates in two phases: first, it trains a preference model to distinguish between successful and unsuccessful reasoning patterns using only trajectory-level outcomes; second, it leverages this learned preference model to provide step-wise weakly-supervised rewards that are combined with sparse terminal rewards during group-relative policy optimization. 
                    By treating consecutive partial trajectories as preference pairs, our method generates dense feedback signals that complement GRPO's group normalization mechanism without requiring step-by-step human annotations.
                    Theoretically, we provide comprehensive guarantees for WS-GRPO establishing preference model consistency under trajectory-level supervision, policy robustness to preference errors with controllable degradation rates, and generalization bounds that decompose error sources across policy learning, preference modeling, and their interaction. 
                    Our experiments on reasoning benchmarks demonstrate that WS-GRPO achieves competitive performance using only weak supervision, making group-relative policy optimization practical when detailed process supervision is limited.
                </p>
            </div>

            <div class="project-entry">
                <h3>SceneAlign: Aligning Multimodal Reasoning to Scene Graphs in Complex Visual Scenes @ McAuley Lab, UCSD</h3>
                <div class="project-callout">
                    <p class="callout-authors">
                        Chuhan Wang, <strong>Jennifer Yuntong Zhang</strong>, Junda Wu, Xintong Li, Tong Yu, Jingbo Shang, Julian McAuley<br>
                        In progress. Target: CVPR 2026.
                    </p>
                    <!-- <div class="project-actions">
                        <a href="https://arxiv.org/pdf/2508.17550" class="btn_pdf">pdf</a>
                        <a href="https://github.com/MAGICS-LAB/hallucination" class="btn_code">code</a>
                    </div> -->
                </div>
                <p>Multimodal Large Language Models (MLLMs) often fail to reason faithfully in complex visual scenes, where multiple objects and intricate relations demand precise grounding of each reasoning step. Prior works improve reasoning via preference-based alignment using simple textual perturbations or answer-based edits, but they do not explicitly tackle grounding failures
                    such as hallucinated entities, incorrect bindings, or omit steps. Motivated by the need for grounding-aware supervision, we propose SceneAlign, a scene-graph-guided preference alignment framework that explicitly supervises grounding during reasoning. 
                    Scene graphs, which encode objects and relations as structured graphs, allow us to (1) identify reasoning-critical nodes and (2) perturb them using four targeted strategies—swap, replace, shorten, overthink—designed to simulate typical grounding errors including hallucination, mis-grounding, skipped inference, and over-specification. 
                    These perturbed scene graphs and their corresponding rationales form ungrounded negative chains-of-thought (CoTs), which are filtered for fluency and paired with their grounded counterparts. 
                    To ensure the model learns preferences for faithful structure-grounded reasoning, we apply Direct Preference Optimization (DPO) to align the model behavior toward coherence and accuracy.. Experiments across seven complex visual reasoning benchmarks show that ourmodel significantly improves both answer correctness and reasoning consistency, establishing a new paradigm for grounding-aware CoT supervision.
                </p>
            </div>

            <!-- <div class="project-entry">
                <h3>Survey Paper on RL @ McAuley Lab, UCSD</h3>
                <p>TBD.</p>
            </div> -->

            <div class="project-entry">
                <h3>Realistic CDSS Drug Dosing with End-to-end Recurrent Q-learning for Dual Vasopressor Control</h3>
                <div class="project-callout">
                    <p class="callout-authors">
                        Will Y. Zou, Jean Feng, Alexandre Kalimouttou, <strong>Jennifer Yuntong Zhang</strong>, Christopher W. Seymour, Romain Pirracchio<br>
                        NeurIPS 2026 Workshop Learning from Time Series for Health.
                    </p>
                    <div class="project-actions">
                        <a href="https://openreview.net/pdf?id=TNj4Cv73Gh" class="btn_pdf">pdf</a>
                        <!-- <a href="https://github.com/JEN6YT/HCL" class="btn_code">code</a> -->
                    </div>
                </div>
                <!-- <p>Reinforcement learning (RL) applications in Clinical Decision Support Systems (CDSS) frequently encounter skepticism from practitioners regarding inoperable dosing decisions. We address this challenge with an end-to-end approach for learning optimal drug dosing and control policies for dual vasopressor administration in intensive care unit (ICU) patients with septic shock. 
                    For realistic drug dosing, we apply action space design that accommodates discrete, continuous, and directional dosing strategies in a system that combines offline conservative Q-learning with a novel recurrent modeling in a replay buffer to capture temporal dependencies in ICU time-series data. 
                    Our comparative analysis of norepinephrine dosing strategies across different action space formulations reveals that the designed action spaces improve interpretability and facilitate clinical adoption while preserving efficacy. 
                    Empirical results on eICUand MIMIC demonstrate that action space design profoundly influences learned behavioral policies. The proposed methods achieve improved patient outcomes of over 15% in survival improvement probability, while aligning with established clinical protocols.
                </p> -->
            </div>
            <div class="project-entry">
                <h3>Methane Emission Drivers and Baseline Calculations</h3>
                <div class="project-callout">
                    <p class="callout-authors">
                        <strong>Jennifer Yuntong Zhang</strong>, Behzad Azadie faraz, Luis A. Seco<br>
                    </p>
                    <div class="project-actions">
                        <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5045567" class="btn_pdf">pdf</a>
                        <a href="https://github.com/JEN6YT/Methane-Emission-Index" class="btn_code">code</a>
                    </div>
                </div>
                <!-- <p>Reinforcement learning (RL) applications in Clinical Decision Support Systems (CDSS) frequently encounter skepticism from practitioners regarding inoperable dosing decisions. We address this challenge with an end-to-end approach for learning optimal drug dosing and control policies for dual vasopressor administration in intensive care unit (ICU) patients with septic shock. 
                    For realistic drug dosing, we apply action space design that accommodates discrete, continuous, and directional dosing strategies in a system that combines offline conservative Q-learning with a novel recurrent modeling in a replay buffer to capture temporal dependencies in ICU time-series data. 
                    Our comparative analysis of norepinephrine dosing strategies across different action space formulations reveals that the designed action spaces improve interpretability and facilitate clinical adoption while preserving efficacy. 
                    Empirical results on eICUand MIMIC demonstrate that action space design profoundly influences learned behavioral policies. The proposed methods achieve improved patient outcomes of over 15% in survival improvement probability, while aligning with established clinical protocols.
                </p> -->
            </div>
        </section>

        <section id="cv">
            <div class="cv-wrapper">
                <!-- Sidebar navigation -->
                <nav class="sidebar">
                    <ul>
                        <li><a href="#basics">Basics</a></li>
                        <li><a href="#education">Education</a></li>
                        <li><a href="#work">Work</a></li>
                        <li><a href="#skills">Skills</a></li>
                        <li><a href="#interest">Interests</a></li>
                    </ul>
                </nav>
            
                <!-- CV Content -->
                <div class="cv-content">
                    <!-- Basics -->
                    <section id="basics" class="card">
                        <h2>Basics</h2>
                        <p><strong>Name:</strong> Yuntong (Jennifer) Zhang</p>
                        <p><strong>Label:</strong> 4th year Undergrad in Engineering Science at University of Toronto</p>
                        <p><strong>Email:</strong> 
                            <a href="mailto:jenniferyt.zhang@mail.utoronto.ca">jenniferyt.zhang@mail.utoronto.ca</a>
                        </p>
                        <p><strong>Summary:</strong> Interested in foundation models, RL, AI for society.</p>
                    </section>
            
                    <!-- Education -->
                    <section id="education" class="card">
                        <h2>Education</h2>
                        <div class="edu-item">
                            <div class="dates">
                                <span class="date-range">2021 - 2026</span>
                                <img src="assets/uoft.png" alt="UT" class="school-logo">
                            </div>
                            <div class="details">
                                <h3>BASc in Engineering Science</h3>
                                <p class="institution">University of Toronto</p>
                                <p class="desc">Graduated with High Distinction.</p>
                            </div>
                        </div>
                    </section>
            
                    <!-- Work -->
                    <section id="work" class="card">
                        <h2>Work</h2>
                        <div class="work-item">
                            <div class="dates">
                                <span class="date-range">Sep 2024 - May 2025</span>
                                <img src="assets/otpp.png" alt="Ontario Teachers' Pension Plan" class="company-logo">
                            </div>
                            <div class="details">
                                <h3>Total Fund Risk Analyst Intern</h3>
                                <p class="company">Ontario Teachers' Pension Plan</p>
                                <ul>
                                    <li>Developed novel statistical algorithms for financial risk calculations such as VaR and Expected Tail Loss.</li>
                                    <li>Researched and implemented LLM multi-agent systems for chatbot Question-Answering with in-house large financial datasets.</li>
                                    <li>Enhanced and maintained current risk calculation pipeline including data extraction, risk scenario generation, risk calculation, and risk
                                        dash-boarding.</li>
                                </ul>
                                <p class="skills">#Langchain, #Python, #SQL, #julia, #Csharp, #flask</p>
                            </div>
                        </div>
                        <hr/>
                        <div class="work-item">
                            <div class="dates">
                                <span class="date-range">May 2024 - Aug 2024</span>
                                <img src="assets/eqbank.png" alt="EQB" class="company-logo">
                            </div>
                            <div class="details">
                                <h3>Business Analyst Intern</h3>
                                <p class="company">EQ Bank</p>
                                <ul>
                                    <li>Conducted comprehensive analysis of the bank's financial reconciliation process, identifying key bottlenecks 
                                        and inefficiencies.</li>
                                    <li>Developed an automated reconciliation system for financial reporting, streamlining the workflow and reducing manual
                                        errors.</li>
                                    <li>Designed and implemented an ETL pipeline for financial data, improving data consistency and reducing data redundancy by 30%.</li>
                                </ul>
                                <p class="skills">#Python, #SQL, #Tableau, #VBA, #Excel</p>
                            </div>
                        </div>
                        <hr/>
                        <div class="work-item">
                            <div class="dates">
                                <span class="date-range">May 2023 - Dec 2023</span>
                                <img src="assets/nrc_cnrc.png" alt="nrc_cnrc" class="company-logo">
                            </div>
                            <div class="details">
                                <h3>Data Engineering Intern</h3>
                                <p class="company">National Reserach Council</p>
                                <ul>
                                    <li>Processed and analyzed large-scale geographical data to investigate factors contributing
                                        to fire incidents along railroads.</li>
                                    <li>Developed and compared machine learning models to predict active fire locations, achieving an accuracy of 89%.</li>
                                    <li>Created an interactive Tableau dashboard to visualize predicted high-risk fire areas along railroad routes, providing actionable
                                        insights for preventive measures.</li>
                                    <li>Collaborated with a cross-functional team to integrate machine learning models into the existing data pipeline, enhancing the overall
                                        efficiency of the data processing workflow.</li>
                                </ul>
                                <p class="skills">#scikit-learn, #Optuna, #geopandas, #Python, #Csharp, #Tableau, #SQL</p>
                            </div>
                        </div>
                    </section>
            
                    <!-- Skills -->
                    <section id="skills" class="card">
                        <div class="skills-container">
                            <div class="skills-content">
                                <h2>Skills</h2>
                                <ul class="skill-list">
                                    <li><strong>Programming:</strong> Python, SQL, C, C++, Julia, HTML, CSS, JavaScript</li>
                                    <li><strong>Deep Learning Programming:</strong> PyTorch, JAX</li>
                                    <li><strong>Machine Learning:</strong>
                                    <ul class="ml-list">
                                        <li>Deep Neural Networks</li>
                                        <li>Computer Vision</li>
                                        <li>Reinforcement Learning</li>
                                        <li>Self-supervised Learning</li>
                                        <li>Representation Learning</li>
                                        <li>Foundation Models</li>
                                    </ul>
                                    </li>
                                </ul>
                            </div>
                        
                            <!-- this empty div will get the image via JS -->
                            <div class="skills-image" id="skills-image">
                                <img src="assets/kugisaki.png" alt="Skills Image" class="skills-illustration"/>
                            </div>
                        </div>
                    </section>

                    <!-- Interests -->
                    <section id="interest" class="card">
                        <h2>Interests</h2>
                        <ul class="interest-list">
                            <li>Data Science, Statistics, Math</li>
                            <li>Reinforcement Learning</li>
                            <li>Model Safety and Privacy</li>
                            <li>Foundation Models and Multi-modal Models</li>
                            <li>AI and Society</li>
                        </ul>
                    </section>
                </div>
            </div>
            
        </section>
    </main>

    <footer>
        <p>&copy; <span id="year"></span> Yuntong Zhang. All rights reserved.</p>
    </footer>


</body>

</html>